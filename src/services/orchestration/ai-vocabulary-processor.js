import { MultiArmedBanditVocabularyAI } from '../../modules/bandit/multi-armed-bandit-vocabulary.js';
import { NgramContextPatternAI } from '../../modules/ngram/ngram-context-pattern.js';
import { BayesianPersonalizationAI } from '../../modules/bayesian/bayesian-personalization.js';
import { DynamicRelationshipLearner } from '../../modules/cooccurrence/dynamic-relationship-learner.js';
import { QualityPredictionModel } from '../../modules/quality/quality-prediction-model.js';
import { EnhancedHybridLanguageProcessor } from '../../core/language/hybrid-processor.js';
import { DictionaryDB } from '../dictionary/dictionary-db.js';

export class AIVocabularyProcessor {
  constructor(banditAI, ngramAI, bayesianAI, cooccurrenceLearner, qualityPredictor, hybridProcessor, dictionary, userId = 'default') {
    this.banditAI = banditAI;
    this.ngramAI = ngramAI;
    this.bayesianAI = bayesianAI;
    this.cooccurrenceLearner = cooccurrenceLearner;
    this.qualityPredictor = qualityPredictor;
    this.hybridProcessor = hybridProcessor;
    this.dictionary = dictionary;
    this.userId = userId; // Add this line

    // TF-IDFé–¢é€£ã®ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£
    this.documents = []; // å‡¦ç†ã•ã‚ŒãŸæ–‡æ›¸ã®é…åˆ—
    this.vocabulary = new Set(); // å…¨ã¦ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªå˜èª
    this.documentTermFrequencies = new Map(); // Map<documentId, Map<term, frequency>>
    this.inverseDocumentFrequencies = new Map(); // Map<term, idf>
    this.documentCount = 0; // æ–‡æ›¸æ•°
    
    this.isInitialized = false;
    console.log('ğŸ§  AIVocabularyProcessoråˆæœŸåŒ–ä¸­...');
  }

  async initialize() {
    if (this.isInitialized) return;
    
    try {
      await Promise.all([
        this.banditAI.initialize(),
        this.ngramAI.initialize(),
        this.bayesianAI.initialize(),
        this.cooccurrenceLearner.initializeLearner(this.userId), // userIdã‚’æ¸¡ã™
        this.qualityPredictor.initializeAIModules(),
        this.hybridProcessor.initialize(),
        this.dictionary.initialize()
      ]);
      this.isInitialized = true;
      console.log('âœ… AIVocabularyProcessoråˆæœŸåŒ–å®Œäº†ã€‚å…¨AIãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã—ãŸã€‚');
    } catch (error) {
      console.error('âŒ AIVocabularyProcessoråˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼:', error.message);
      throw error;
    }
  }

  /**
   * ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã‚’å‡¦ç†ã—ã€5ã¤ã®AIãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’çµ±åˆã—ã¦åˆ†æçµæœã‚’ç”Ÿæˆã—ã¾ã™ã€‚
   * @param {string} text - ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ
   * @param {string} userId - ãƒ¦ãƒ¼ã‚¶ãƒ¼ID (å€‹äººé©å¿œç”¨)
   * @returns {Promise<Object>} çµ±åˆåˆ†æçµæœ
   */
  async processText(text, userId = 'default') {
    if (!this.isInitialized) {
      await this.initialize();
    }

    // cooccurrenceLearnerãŒã¾ã åˆæœŸåŒ–ã•ã‚Œã¦ã„ãªã„å ´åˆã€ã“ã“ã§åˆæœŸåŒ–
    if (!this.cooccurrenceLearner.isInitialized) {
        await this.cooccurrenceLearner.initializeLearner(userId);
    }

    console.log(`âœ¨ AIVocabularyProcessor: ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†é–‹å§‹ - "${text}"`);
    const startTime = Date.now();
    
    let result = {
      success: true,
      originalText: text,
      processedTokens: [],
      dictionaryLookups: [],
      optimizedVocabulary: null,
      predictedContext: null,
      adaptedContent: null,
      cooccurrenceAnalysis: null,
      qualityPrediction: null,
      processingTime: 0
    };

    try {
      // 1. å½¢æ…‹ç´ è§£æã¨è¾æ›¸ãƒ«ãƒƒã‚¯ã‚¢ãƒƒãƒ—
      const step1Start = Date.now();
      const processed = await this.hybridProcessor.processText(text);
      console.log(`â±ï¸ 1.å½¢æ…‹ç´ è§£æ: ${Date.now() - step1Start}ms`);
      
      // enhancedTermsã¾ãŸã¯tokensã‹ã‚‰çµ±ä¸€çš„ã«å‡¦ç†
      const tokens = processed.tokens || processed.enhancedTerms || [];
      
      if (tokens.length > 0) {
        // 0. å‡¦ç†æ¸ˆã¿ãƒˆãƒ¼ã‚¯ãƒ³ã®ä¿å­˜
        result.processedTokens = tokens;
        result.enhancedTerms = tokens; // äº’æ›æ€§ã®ãŸã‚
        
        const lookupResults = await Promise.all(
          tokens.map(token => this.dictionary.lookup(token.surface || token.term))
        );
        result.dictionaryLookups = lookupResults.filter(Boolean);
        
        // 2. å¤šè…•ãƒãƒ³ãƒ‡ã‚£ãƒƒãƒˆã«ã‚ˆã‚‹èªå½™æœ€é©åŒ–
        const step2Start = Date.now();
        const candidateVocabularies = tokens.filter(t => !['åŠ©è©', 'åŠ©å‹•è©', 'è¨˜å·'].includes(t.pos)).map(t => t.surface || t.term);
        result.optimizedVocabulary = await this.banditAI.selectVocabulary(candidateVocabularies);
        console.log(`â±ï¸ 2.èªå½™æœ€é©åŒ–: ${Date.now() - step2Start}ms`);
        
        // 3. N-gramã«ã‚ˆã‚‹æ–‡è„ˆäºˆæ¸¬
        const step3Start = Date.now();
        result.predictedContext = await this.ngramAI.predictContext(text);
        console.log(`â±ï¸ 3.N-gramäºˆæ¸¬: ${Date.now() - step3Start}ms`);
        
        // 4. ãƒ™ã‚¤ã‚¸ã‚¢ãƒ³å€‹äººé©å¿œ
        const step4Start = Date.now();
        const contentFeatures = this._extractFeaturesForBayesian(tokens, result.predictedContext);
        result.adaptedContent = await this.bayesianAI.adaptForUser(userId, { text: text, features: contentFeatures });
        console.log(`â±ï¸ 4.ãƒ™ã‚¤ã‚¸ã‚¢ãƒ³é©å¿œ: ${Date.now() - step4Start}ms`);
        
        // 5. å…±èµ·é–¢ä¿‚å­¦ç¿’
        const step5Start = Date.now();
        // DynamicRelationshipLearnerã®analyzeãƒ¡ã‚½ãƒƒãƒ‰ã‚’å‘¼ã³å‡ºã™
        await this.cooccurrenceLearner.analyze(text, result.optimizedVocabulary);
        result.cooccurrenceAnalysis = {
          learningStats: this.cooccurrenceLearner.getLearningStats(),
          relatedTerms: this.cooccurrenceLearner.getUserRelationsData()
        };
        console.log(`â±ï¸ 5.å…±èµ·å­¦ç¿’: ${Date.now() - step5Start}ms`);
        
        // 6. å“è³ªäºˆæ¸¬
        const step6Start = Date.now();
        result.qualityPrediction = await this.qualityPredictor.predictQuality({
          text: text,
          metadata: {
            frequency: result.optimizedVocabulary ? 1 : 0, // ä»®ã®é »åº¦
            relevanceScore: result.predictedContext?.confidence || 0.5 // æ–‡è„ˆäºˆæ¸¬ã®ä¿¡é ¼åº¦ã‚’é–¢é€£æ€§ã‚¹ã‚³ã‚¢ã¨ã—ã¦åˆ©ç”¨
          }
        });
        console.log(`â±ï¸ 6.å“è³ªäºˆæ¸¬: ${Date.now() - step6Start}ms`);

        // 7. TF-IDFã‚¹ã‚³ã‚¢è¨ˆç®—
        result.tfidfScores = await this.calculateTfIdf(text, tokens);
        
        result.success = true;
      } else {
        console.warn('âš ï¸ ãƒˆãƒ¼ã‚¯ãƒ³è§£æçµæœãŒç©ºã§ã™');
      }

    } catch (error) {
      console.error('âŒ AIVocabularyProcessorå‡¦ç†ã‚¨ãƒ©ãƒ¼:', error.message);
      result.success = false;
      result.error = error.message;
    } finally {
      result.processingTime = Date.now() - startTime;
      console.log(`âœ… AIVocabularyProcessor: å‡¦ç†å®Œäº† (${result.processingTime}ms)`);
    }

    return result;
  }

  /**
   * ãƒ™ã‚¤ã‚¸ã‚¢ãƒ³AIç”¨ã®ç‰¹å¾´é‡ã‚’æŠ½å‡ºã—ã¾ã™ã€‚
   * @param {Array} tokens - å½¢æ…‹ç´ è§£æã•ã‚ŒãŸãƒˆãƒ¼ã‚¯ãƒ³
   * @param {Object} predictedContext - N-gramã«ã‚ˆã‚‹æ–‡è„ˆäºˆæ¸¬çµæœ
   * @returns {Object} ãƒ™ã‚¤ã‚¸ã‚¢ãƒ³AIç”¨ã®ç‰¹å¾´é‡
   * [Private method]
   */
  _extractFeaturesForBayesian(tokens, predictedContext) {
    const features = {};
    
    // ä¾‹: å“è©ã®å‡ºç¾é »åº¦ã‚’ç‰¹å¾´é‡ã¨ã—ã¦è¿½åŠ 
    tokens.forEach(token => {
      const posFeature = `pos_${token.pos}`;
      features[posFeature] = (features[posFeature] || 0) + 1;
    });

    // ä¾‹: æ–‡è„ˆã‚«ãƒ†ã‚´ãƒªã‚’ç‰¹å¾´é‡ã¨ã—ã¦è¿½åŠ 
    if (predictedContext && predictedContext.predictedCategory) {
      features[`context_${predictedContext.predictedCategory}`] = 1;
    }

    // ãã®ä»–ã®ç‰¹å¾´é‡ï¼ˆä¾‹: æ„Ÿæƒ…ã€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãªã©ï¼‰ã‚’ã“ã“ã«è¿½åŠ å¯èƒ½
    // features['sentiment_positive'] = 1; // ä»®
    // features['keyword_AI'] = 1; // ä»®

    return features;
  }

  /**
   * TF-IDFã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ã—ã€çµæœã«å«ã‚ã¾ã™ã€‚
   * @param {string} text - å‡¦ç†ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ
   * @param {Array} tokens - å½¢æ…‹ç´ è§£æã•ã‚ŒãŸãƒˆãƒ¼ã‚¯ãƒ³
   * @returns {Object} TF-IDFã‚¹ã‚³ã‚¢ã‚’å«ã‚€ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
   */
  async calculateTfIdf(text, tokens) {
    const documentId = this.documentCount++;
    const termFrequencies = new Map();

    for (const token of tokens) {
      const term = token.surface || token.term;
      termFrequencies.set(term, (termFrequencies.get(term) || 0) + 1);
      this.vocabulary.add(term);
    }
    this.documentTermFrequencies.set(documentId, termFrequencies);
    this.documents.push(text);

    // IDFã®æ›´æ–°
    for (const term of this.vocabulary) {
      let docCount = 0;
      for (const [docId, tfMap] of this.documentTermFrequencies.entries()) {
        if (tfMap.has(term)) {
          docCount++;
        }
      }
      this.inverseDocumentFrequencies.set(term, Math.log(this.documentCount / (docCount + 1)));
    }

    const tfidfScores = {};
    for (const [term, tf] of termFrequencies.entries()) {
      const idf = this.inverseDocumentFrequencies.get(term) || 0;
      tfidfScores[term] = tf * idf;
    }

    return tfidfScores;
  }

  /**
   * ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’å„AIãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã«ä¼æ’­ã—ã¾ã™ã€‚
   * @param {string} userId - ãƒ¦ãƒ¼ã‚¶ãƒ¼ID
   * @param {string} vocabulary - è©•ä¾¡ã•ã‚ŒãŸèªå½™
   * @param {number} rating - ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®è©•ä¾¡
   * @param {string} contextText - è©•ä¾¡æ™‚ã®æ–‡è„ˆãƒ†ã‚­ã‚¹ãƒˆ
   */
  async propagateFeedback(userId, vocabulary, rating, contextText) {
    if (!this.isInitialized) {
      await this.initialize();
    }
    
    console.log(`ğŸ”„ ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ä¼æ’­é–‹å§‹: ${vocabulary} (Rating: ${rating})`);
    
    try {
      await this.banditAI.updateRewards(vocabulary, rating);
      
      // N-gram AIã«å­¦ç¿’ã•ã›ã‚‹
      const predictedContext = await this.ngramAI.predictContext(contextText); // ã“ã“ã§äºˆæ¸¬ã—ç›´ã™ã®ã¯ã€æœ€æ–°ã®å­¦ç¿’çŠ¶æ…‹ã‚’åæ˜ ã™ã‚‹ãŸã‚
      await this.ngramAI.learnPattern(contextText, { category: predictedContext.predictedCategory });

      // ãƒ™ã‚¤ã‚¸ã‚¢ãƒ³AIã«å­¦ç¿’ã•ã›ã‚‹
      const features = new Map();
      if (typeof vocabulary === 'string') {
        features.set(vocabulary, 1); // è©•ä¾¡ã•ã‚ŒãŸèªå½™è‡ªä½“ã‚’ç‰¹å¾´é‡ã¨ã™ã‚‹
      }
      features.set('is_rated_positive', rating > 0.5 ? 1 : 0); // è©•ä¾¡ãŒãƒã‚¸ãƒ†ã‚£ãƒ–ã‹ã©ã†ã‹ã®ç‰¹å¾´é‡
      // contextText ã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡ºã—ã€ç‰¹å¾´é‡ã¨ã—ã¦è¿½åŠ ã™ã‚‹ã“ã¨ã‚‚å¯èƒ½
      const contextAnalysis = await this.processText(contextText);
      const contextKeywords = contextAnalysis.enhancedTerms ? contextAnalysis.enhancedTerms.map(term => term.term) : [];
      contextKeywords.forEach(kw => features.set(`keyword_${kw}`, 1));

      await this.bayesianAI.learnUserBehavior(userId, {
        class: predictedContext.predictedCategory,
        features: features,
      });
      
      if (typeof vocabulary === 'string') {
        await this.cooccurrenceLearner.learnFromFeedback(vocabulary, rating, contextText);
      }
      
      // QualityPredictionModelã®learnFromFeedbackã¯ç›´æ¥å‘¼ã°ã‚Œãªã„ãŸã‚ã€ã“ã“ã§ã¯å‘¼ã³å‡ºã•ãªã„
      // await this.qualityPredictor.learnFromFeedback(originalContent, appliedSuggestion, beforeScore, afterScore);

      console.log('âœ… ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ä¼æ’­å®Œäº†ã€‚');
      
    } catch (error) {
      console.error('âŒ ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ä¼æ’­ã‚¨ãƒ©ãƒ¼:', error.message);
    }
  }
}